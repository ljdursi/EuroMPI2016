{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Dataframes\n",
    "\n",
    "Built on top of RDDs are dataframes, Pandas- or R-like column-organized tables of data.  In this example from [Data Bricks](https://databricks.com/blog/2015/06/02/statistical-and-mathematical-functions-with-dataframes-in-spark.html), we take a look how these aer used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Dataframes allow SQL-like queriying and calculations.  This is more than a familiar interface; by using such an approach, mature SQL query optimizers can be brought to beear to re-structure the movement of data, bringing a powerful runtime approach to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "from pyspark import SparkContext, SQLContext\n",
    "sc = SparkContext(\"local[4]\")\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That done, we write some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import rand, randn\n",
    "df = sqlc.range(0, 100)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+\n",
      "| id|            uniform|             normal|\n",
      "+---+-------------------+-------------------+\n",
      "|  0|0.41371264720975787| 0.5888539012978773|\n",
      "|  1| 0.7311719281896606| 0.8645537008427937|\n",
      "|  2| 0.9031701155118229| 1.2524569684217643|\n",
      "|  3|0.09430205113458567| -2.573636861034734|\n",
      "|  4|0.38340505276222947| 0.5469737451926588|\n",
      "|  5| 0.5569246135523511|0.17431283601478723|\n",
      "|  6| 0.4977441406613893|-0.7040284633147095|\n",
      "|  7| 0.2076666106201438| 0.4637547571868822|\n",
      "|  8| 0.9571919406508957|  0.920722532496133|\n",
      "|  9| 0.7429395461204413|-1.4353459012380192|\n",
      "+---+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(\"id\", \n",
    "                  rand(seed=10).alias(\"uniform\"), \n",
    "                  randn(seed=27).alias(\"normal\"))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+\n",
      "|summary|                id|             uniform|              normal|\n",
      "+-------+------------------+--------------------+--------------------+\n",
      "|  count|               100|                 100|                 100|\n",
      "|   mean|              49.5|    0.49686601567822|-0.01216928004517...|\n",
      "| stddev|29.011491975882016| 0.28826347846677686|  1.0617174284468838|\n",
      "|    min|                 0|0.002510505496357...| -2.6620895295953004|\n",
      "|    max|                99|  0.9958062482976284|   2.750429557170309|\n",
      "+-------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+------------------+\n",
      "|    avg(uniform)|        min(uniform)|      max(uniform)|\n",
      "+----------------+--------------------+------------------+\n",
      "|0.49686601567822|0.002510505496357...|0.9958062482976284|\n",
      "+----------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select([mean('uniform'), min('uniform'), max('uniform')]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025093879241165065"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.cov('uniform', 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+--------------------+\n",
      "| id|            uniform|             normal|          cos_normal|\n",
      "+---+-------------------+-------------------+--------------------+\n",
      "|  0|0.41371264720975787| 0.5888539012978773| -0.8481662251719577|\n",
      "|  1| 0.7311719281896606| 0.8645537008427937|  0.6592023710354442|\n",
      "|  2| 0.9031701155118229| 1.2524569684217643|-0.01543032849405...|\n",
      "|  3|0.09430205113458567| -2.573636861034734|  -0.894868255256957|\n",
      "|  4|0.38340505276222947| 0.5469737451926588| -0.9567608933620207|\n",
      "|  5| 0.5569246135523511|0.17431283601478723|   0.457834069473377|\n",
      "|  6| 0.4977441406613893|-0.7040284633147095| -0.2848514172214892|\n",
      "|  7| 0.2076666106201438| 0.4637547571868822| -0.9741795801191937|\n",
      "|  8| 0.9571919406508957|  0.920722532496133|  0.8784823756819166|\n",
      "|  9| 0.7429395461204413|-1.4353459012380192| -0.9186125933094329|\n",
      "+---+-------------------+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('id','uniform','normal',(cos(df.normal*2*3.14159).alias('cos_normal')))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
